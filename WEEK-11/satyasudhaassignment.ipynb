{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fCEDCU_qrC0"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "Name: Satya Sudha\n",
        "Week 11\n",
        "Xgboost with 5 CV\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the required packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from xgboost import XGBClassifier\n"
      ],
      "metadata": {
        "id": "4-EXiqwiduGa"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading the datasets\n",
        "data_100 = pd.read_csv('data_100.csv')\n",
        "data_1000 = pd.read_csv('data_1000.csv')\n",
        "data_10000 = pd.read_csv('data_10000.csv')\n",
        "data_100000 = pd.read_csv('data_100000.csv')\n",
        "data_1000000 = pd.read_csv('data_1000000.csv')\n",
        "data_10000000 = pd.read_csv('data_10000000.csv')"
      ],
      "metadata": {
        "id": "PYISXobMduDI"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datasets = {\n",
        "    100: data_100,\n",
        "    1000: data_1000,\n",
        "    10000: data_10000,\n",
        "    100000: data_100000,\n",
        "    1000000: data_1000000,\n",
        "    10000000: data_10000000\n",
        "}\n",
        "\n",
        "results = []\n",
        "\n",
        "for size, df in datasets.items():\n",
        "    print(f\"▶ Working on dataset of size {size}\")\n",
        "\n",
        "    X = df.drop(columns='outcome')\n",
        "    y = df['outcome']\n",
        "\n",
        "    model = XGBClassifier(\n",
        "        use_label_encoder=False,\n",
        "        eval_metric='logloss',\n",
        "        verbosity=0\n",
        "    )\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
        "    mean_accuracy = np.mean(scores)\n",
        "\n",
        "    end_time = time.time()\n",
        "    elapsed_time = end_time - start_time\n",
        "\n",
        "    results.append({\n",
        "        'Method used': 'XGBoost (Python, sklearn, 5-fold CV)',\n",
        "        'Dataset size': size,\n",
        "        'Testing-set predictive performance': mean_accuracy,\n",
        "        'Time taken for the model to be fit (seconds)': elapsed_time\n",
        "    })\n",
        "\n",
        "# Converting results to DataFrame\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "# Prining the results\n",
        "print(results_df)\n",
        "\n",
        "# Saving in the table format\n",
        "results_df.to_csv('xgboost_python_results.csv', index=False)\n"
      ],
      "metadata": {
        "id": "9eK3xbmseRrO",
        "outputId": "3d821f44-ee24-4962-b360-0463097d72d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "▶ Working on dataset of size 100\n",
            "▶ Working on dataset of size 1000\n",
            "▶ Working on dataset of size 10000\n",
            "▶ Working on dataset of size 100000\n",
            "▶ Working on dataset of size 1000000\n",
            "▶ Working on dataset of size 10000000\n",
            "                            Method used  Dataset size  \\\n",
            "0  XGBoost (Python, sklearn, 5-fold CV)           100   \n",
            "1  XGBoost (Python, sklearn, 5-fold CV)          1000   \n",
            "2  XGBoost (Python, sklearn, 5-fold CV)         10000   \n",
            "3  XGBoost (Python, sklearn, 5-fold CV)        100000   \n",
            "4  XGBoost (Python, sklearn, 5-fold CV)       1000000   \n",
            "5  XGBoost (Python, sklearn, 5-fold CV)      10000000   \n",
            "\n",
            "   Testing-set predictive performance  \\\n",
            "0                            0.860000   \n",
            "1                            0.942000   \n",
            "2                            0.975300   \n",
            "3                            0.987300   \n",
            "4                            0.991825   \n",
            "5                            0.993127   \n",
            "\n",
            "   Time taken for the model to be fit (seconds)  \n",
            "0                                      0.387820  \n",
            "1                                      0.302068  \n",
            "2                                      0.858006  \n",
            "3                                      4.127322  \n",
            "4                                     58.762435  \n",
            "5                                    453.998794  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As the dataset size increases, the XGBoost model's performance improves significantly. On smaller datasets, such as the one with just 100 samples, the model achieved an accuracy of 86%. However, as the dataset grows, so does the accuracy, reaching 99.31% on the largest dataset of 10 million samples. This demonstrates that the model becomes more accurate with more data, which is expected for machine learning models. Along with the improved accuracy, the time taken to fit the model also increases with the size of the dataset. For the 100-sample dataset, the model was trained in just 0.39 seconds, while for the 10 million-sample dataset, it took approximately 454 seconds (or 7.5 minutes). This trade-off between training time and performance is important to consider: smaller datasets allow for faster training and good accuracy, but larger datasets provide even better accuracy at the cost of longer computation times."
      ],
      "metadata": {
        "id": "oWnzYYDLkjs8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "71IezjQZkk4J"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}