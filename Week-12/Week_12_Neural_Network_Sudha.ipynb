{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Week 12 - Neural Network**"
      ],
      "metadata": {
        "id": "jFK2pPSQw2xb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model uses an Adam optimizer for training efficiency through user-defined activations in hidden layers while implementing linear activation at its output section for regression tasks. MSE serves as the training and evaluation criterion when compiling the model."
      ],
      "metadata": {
        "id": "amdUan3Fw1Ny"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# libraries"
      ],
      "metadata": {
        "id": "nooGmy_Sd2VG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input # Use Input Layer explicitly\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error # To calculate MSE on original scale\n",
        "import time\n",
        "import os"
      ],
      "metadata": {
        "id": "avktgVYly9n_"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Seed"
      ],
      "metadata": {
        "id": "NNof_v7oejmW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Random seeds\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "metadata": {
        "id": "f2TU807velr2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Global Variables"
      ],
      "metadata": {
        "id": "hQfmB4Jme4O1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_SIZES = [1000, 10000, 100000]\n",
        "# File naming convention updated\n",
        "FILE_NAME_TEMPLATE = \"synthetic_data_{}k.csv\"\n",
        "# Feature and Target column names updated\n",
        "FEATURE_COLUMNS = ['VarA', 'VarB', 'VarC', 'VarD']\n",
        "TARGET_COLUMN = 'Target'\n",
        "\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 32\n",
        "VALIDATION_SPLIT = 0.3\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "# List to store results from all models and sizes\n",
        "dl_results = []"
      ],
      "metadata": {
        "id": "FltN_g-he9-h"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions"
      ],
      "metadata": {
        "id": "m_qB4MT9fDMQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model_simple(n_features, layer_nodes, model_name, activation='relu'):\n",
        "    \"\"\"Builds simple Keras Sequential models.\"\"\"\n",
        "    model = Sequential(name=model_name)\n",
        "    model.add(Input(shape=(n_features,))) # Use Input layer\n",
        "    for nodes in layer_nodes:\n",
        "        model.add(Dense(nodes, activation=activation))\n",
        "    model.add(Dense(1, activation='linear')) # Linear output for regression\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='mean_squared_error', # Use MSE for loss\n",
        "                  metrics=['mean_squared_error']) # Track MSE metric\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "rEsSWGtzd_uq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train and test"
      ],
      "metadata": {
        "id": "wAcZL3A-fmM0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for size in DATA_SIZES:\n",
        "    print(f\"\\n Data Size: {size}\")\n",
        "    data_file = FILE_NAME_TEMPLATE.format(size // 1000) # Use new file name format\n",
        "\n",
        "    # Data Loading and Preparation\n",
        "    if not os.path.exists(data_file):\n",
        "        print(f\"ERROR: Data file {data_file} not found. Please generate it first.\")\n",
        "        # Add placeholder results for the two remaining configurations for this size\n",
        "        configs_to_skip = [\n",
        "            '1 hidden layer 4 nodes',\n",
        "            '2 hidden layers 4 nodes each'\n",
        "            # Model 3 removed\n",
        "        ]\n",
        "        for config_name in configs_to_skip:\n",
        "             dl_results.append({\n",
        "                'Data size': size,\n",
        "                'Configuration': config_name,\n",
        "                'Training error (MSE)': np.nan,\n",
        "                'Validation error (MSE)': np.nan,\n",
        "                'Time of execution (s)': np.nan\n",
        "            })\n",
        "        continue # Skip to the next data size\n",
        "\n",
        "    # Load data\n",
        "    df = pd.read_csv(data_file)\n",
        "    print(f\"  Loaded {data_file}\")\n",
        "\n",
        "    # Select features (X) and target (y) using new column names\n",
        "    X = df[FEATURE_COLUMNS]\n",
        "    y = df[TARGET_COLUMN]\n",
        "\n",
        "    # Check target variable stats\n",
        "    print(f\"  '{TARGET_COLUMN}' variable stats for size {size}:\")\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        X, y, test_size=VALIDATION_SPLIT, random_state=RANDOM_STATE\n",
        "    )\n",
        "\n",
        "    # Scale Features (X)\n",
        "    x_scaler = StandardScaler()\n",
        "    X_train_scaled = x_scaler.fit_transform(X_train)\n",
        "    X_val_scaled = x_scaler.transform(X_val)\n",
        "    n_features = X_train_scaled.shape[1]\n",
        "\n",
        "    # Scale Target (Y) - Crucial due to potentially large values\n",
        "    y_scaler = StandardScaler()\n",
        "    # Reshape y for scaler (expects 2D array)\n",
        "    y_train_scaled = y_scaler.fit_transform(y_train.values.reshape(-1, 1))\n",
        "    y_val_scaled = y_scaler.transform(y_val.values.reshape(-1, 1))\n",
        "    print(\"  Features and Target Scaled.\")\n",
        "\n",
        "    # Train Model 1: 1 hidden layer 4 nodes\n",
        "    print(\"\\nTraining Model: 1 hidden layer 4 nodes\")\n",
        "    model_1L = build_model_simple(n_features, [4], model_name=\"1L_4N\")\n",
        "\n",
        "    start_time_1L = time.time()\n",
        "    history_1L = model_1L.fit(\n",
        "        X_train_scaled, y_train_scaled,\n",
        "        validation_data=(X_val_scaled, y_val_scaled),\n",
        "        epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=0\n",
        "    )\n",
        "    end_time_1L = time.time()\n",
        "    execution_time_1L = end_time_1L - start_time_1L\n",
        "\n",
        "    # Evaluate Model 1 (on original scale)\n",
        "    pred_train_scaled_1L = model_1L.predict(X_train_scaled, verbose=0)\n",
        "    pred_val_scaled_1L = model_1L.predict(X_val_scaled, verbose=0)\n",
        "    pred_train_orig_1L = y_scaler.inverse_transform(pred_train_scaled_1L)\n",
        "    pred_val_orig_1L = y_scaler.inverse_transform(pred_val_scaled_1L)\n",
        "    train_mse_orig_1L = mean_squared_error(y_train, pred_train_orig_1L)\n",
        "    val_mse_orig_1L = mean_squared_error(y_val, pred_val_orig_1L)\n",
        "\n",
        "    print(f\"    Training MSE (original scale): {train_mse_orig_1L:.4f}\")\n",
        "    print(f\"    Validation MSE (original scale): {val_mse_orig_1L:.4f}\")\n",
        "    print(f\"    Execution Time: {execution_time_1L:.2f} seconds\")\n",
        "\n",
        "    # Store results for Model 1\n",
        "    dl_results.append({\n",
        "        'Data size': size,\n",
        "        'Configuration': '1 hidden layer 4 nodes',\n",
        "        'Training error (MSE)': train_mse_orig_1L,\n",
        "        'Validation error (MSE)': val_mse_orig_1L,\n",
        "        'Time of execution (s)': execution_time_1L\n",
        "    })\n",
        "\n",
        "    # Train Model 2: 2 hidden layers 4 nodes each\n",
        "    print(\"\\nTraining Model: 2 hidden layers 4 nodes each\")\n",
        "    model_2L = build_model_simple(n_features, [4, 4], model_name=\"2L_4N_4N\")\n",
        "\n",
        "    start_time_2L = time.time()\n",
        "    history_2L = model_2L.fit(\n",
        "        X_train_scaled, y_train_scaled,\n",
        "        validation_data=(X_val_scaled, y_val_scaled),\n",
        "        epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=0\n",
        "    )\n",
        "    end_time_2L = time.time()\n",
        "    execution_time_2L = end_time_2L - start_time_2L\n",
        "\n",
        "    # Evaluate Model 2 (on original scale)\n",
        "    pred_train_scaled_2L = model_2L.predict(X_train_scaled, verbose=0)\n",
        "    pred_val_scaled_2L = model_2L.predict(X_val_scaled, verbose=0)\n",
        "    pred_train_orig_2L = y_scaler.inverse_transform(pred_train_scaled_2L)\n",
        "    pred_val_orig_2L = y_scaler.inverse_transform(pred_val_scaled_2L)\n",
        "    train_mse_orig_2L = mean_squared_error(y_train, pred_train_orig_2L)\n",
        "    val_mse_orig_2L = mean_squared_error(y_val, pred_val_orig_2L)\n",
        "\n",
        "    print(f\"    Training MSE (original scale): {train_mse_orig_2L:.4f}\")\n",
        "    print(f\"    Validation MSE (original scale): {val_mse_orig_2L:.4f}\")\n",
        "    print(f\"    Execution Time: {execution_time_2L:.2f} seconds\")\n",
        "\n",
        "    # Store results for Model 2\n",
        "    dl_results.append({\n",
        "        'Data size': size,\n",
        "        'Configuration': '2 hidden layers 4 nodes each',\n",
        "        'Training error (MSE)': train_mse_orig_2L,\n",
        "        'Validation error (MSE)': val_mse_orig_2L,\n",
        "        'Time of execution (s)': execution_time_2L\n",
        "    })\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMxx0zvwfojZ",
        "outputId": "a4185de0-2e45-4771-fa08-e5900b632c7e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Data Size: 1000\n",
            "  Loaded synthetic_data_1k.csv\n",
            "  'Target' variable stats for size 1000:\n",
            "  Features and Target Scaled.\n",
            "\n",
            "Training Model: 1 hidden layer 4 nodes\n",
            "    Training MSE (original scale): 14552467.0555\n",
            "    Validation MSE (original scale): 14419139.8553\n",
            "    Execution Time: 9.25 seconds\n",
            "\n",
            "Training Model: 2 hidden layers 4 nodes each\n",
            "    Training MSE (original scale): 73428227.4457\n",
            "    Validation MSE (original scale): 74458843.2386\n",
            "    Execution Time: 9.89 seconds\n",
            "\n",
            " Data Size: 10000\n",
            "  Loaded synthetic_data_10k.csv\n",
            "  'Target' variable stats for size 10000:\n",
            "  Features and Target Scaled.\n",
            "\n",
            "Training Model: 1 hidden layer 4 nodes\n",
            "    Training MSE (original scale): 9462526.3514\n",
            "    Validation MSE (original scale): 10213397.9534\n",
            "    Execution Time: 32.30 seconds\n",
            "\n",
            "Training Model: 2 hidden layers 4 nodes each\n",
            "    Training MSE (original scale): 6405523.1911\n",
            "    Validation MSE (original scale): 6441236.3064\n",
            "    Execution Time: 36.11 seconds\n",
            "\n",
            " Data Size: 100000\n",
            "  Loaded synthetic_data_100k.csv\n",
            "  'Target' variable stats for size 100000:\n",
            "  Features and Target Scaled.\n",
            "\n",
            "Training Model: 1 hidden layer 4 nodes\n",
            "    Training MSE (original scale): 138168947.2204\n",
            "    Validation MSE (original scale): 135043017.2930\n",
            "    Execution Time: 319.26 seconds\n",
            "\n",
            "Training Model: 2 hidden layers 4 nodes each\n",
            "    Training MSE (original scale): 56407593.0875\n",
            "    Validation MSE (original scale): 56622360.8590\n",
            "    Execution Time: 349.49 seconds\n"
          ]
        }
      ]
    }
  ]
}